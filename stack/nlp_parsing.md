### Grammars and Parsing
1. Grammar 문법: 문장의 구조적 성질을 규칙으로 표현한 것 **A set of rewrite rules**, Context Free Grammar(CFG)
2. Syntactic Parsing 구문 분석기: 문법을 이용하여 문장의 구조를 찾아내는 process, Tree형태로 표현. 몇 개의 형태소 -> 구문 요소(구: phrase) -> 구문 요소들간의 결합구조: Tree형태로 최종 구문 구조; S> NP, VP > NP+PP, Pro, V, Det+N, Prep+NP 등 // Produces all possible parse trees -> Syntactic Ambiguity 발생
    1. Given 1) a string of terminals and 2)a CFG, determine if the string can be generated by the CFG / Top-Down, Bottom-up, Caching(Memoizing)
    2. Dynamic Programming Parsing Methods: **CKY Parser**(First grammar -> Chomsky normal form(CNF), O(n^2) cells, O(n) split points —> O(n^3) in the end), Earley’s parser, Tomita’s Parser(LR Parser)

### Language Modeling with N-grams
- Conditional Probability, Language Modeling, Markov Assumption —> N-Gram Models
- Maximum Likelihood Estimation
- Problems 1) the perils of overfitting, 2) zeros of not? Zipf’s law
- ** Smoothing** 1) Robin Hood, 2) Laplace(Add-one), 3) Add-k +a) Backoff, Interpolation
- Evaluation: **Perplexity** an intrinsic evaluation measure of how well a model “fits” the test data; the probability of the test set(assigned by the language model), normalized by the number of words. Minimize perplexity == Maximizing probability == Better model
- Unknown words: Out Of Vocabulary(OOV) <UNK>

### POS Tagging, Sequence Labeling, and HMM
1. Part Of Speech Tagging: the lowest level of syntactic analysis. —>는 ambiguity 발생 -> probability를 활용하자(HMM)
2. Sequence Labeling
3. Hidden Markov Models: A set of states, Transition probabilities, Distinguished start and end states
    1. Decoding: Forward Algorithm, The Viterbi algorithm
4. Baum-Welch algorithm/ EM algorithm

### Statistical Parsing
- Phrase Chunking as Sequence Labeling: B(begin)I(inside)O(other) tagging
- Probabilistic(P)CKY Parser
- 한국어 구문 분석: Dependency Grammars 의존문법을 이용 1) 투영의 원칙(엇갈린 의존관계X) 2) 지배성분(Head) 유일의 원칙(임의의 문장 성분은 다른 하나의 문장 성분만을 수식) 3) 지배성분 후위의 원칙

### Neural Shift-Reduce Dependency Parsing
- Shift-Reduce dependency parser
- Shift: Push the next word in the buffer onto the stack
- Reduce: Replace a set of the top elements on the stack with a constituent composed of them,

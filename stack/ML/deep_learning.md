Contents for Ch1-5 of Deep Learning textbook at www.deeplearningbook.org


#### Chapter1 Introduction
1.1 Who should read this book?<br>
1.2 Historical Trends in Deep Learning<br>

#### Part1 Applied Math and Machine Learning Basics
#### Chapter2 Linear Algebra
2.1 Scalars, Vectors, Matrices and Tensors<br>
2.2 Multiplying Matrices and Vectors<br>
2.3 Identity and Inverse Matrices<br>
2.4 Linear Dependence and Span<br>
2.5 Norms<br>
2.6 Special Kinds of Matrices and Vectors<br>
2.7 Eigendecomposition<br>
2.8 Singular Value Decomposition<br>
2.9 The Moore-Penrose Pseudoinverse<br>
2.10 The Trace Operator<br>
2.11 The Determinant<br>
2.12 Example: Principal components Analysis<br>

#### Chapter3 Probability and Information Theory
3.1 Why Probability?<br>
3.2 Random Variables<br>
3.3 Probability Distributions<br>
- discrete variables and pmf
- continuous variable and pdf

3.4 Marginal Probability<br>
3.5 Conditional Probability<br>
3.6 The Chain Rule of Conditional Probabilities<br>
3.7 Independence and Conditional Independence<br>
3.8 Expectation, Variance and Covariance<br>
3.9 Common Probability Distributions<br>
- Bernoulli Distribution
- Multinoulli Distribution
- Gaussian Distirbution
- Exponential Distirbution
- Laplace Distirbution
- Dirac Distirbution and Empirical Distirbution
- Mixtures of Distirbutions

3.10 Useful Properties of Commom Functions<br>
3.11 Bayes' Rule<br>
3.12 Technical Details of Continuous Variables<br>
3.13 Information Theory<br>
- KL Divergence

3.14 Structured Probabilistic Models<br>

#### Chapter 4 Numerical Computation
4.1 Overflow and Underflow<br>
4.2 Poor Conditioning<br>
4.3 Gradient-Based Optimization<br>
- Jacobian and Hessian Matrices

4.4 Constrained Optimization<br>
4.5 Example: Linear Least Squares<br>

#### Chapter 5 Machine Learning Basics
5.1 Learning Algorithms<br>
- Task, Performance measure, Experience

5.2 Capacity, Overfitting and Underfitting<br>
5.3 Hyperparameters and Validation sets<br>
5.4 Estimators, Bias and Variance<br>
5.5 Maximum Likelihood Estimation<br>
5.6 Bayesian Statistics<br>
5.7 Supervised Learning Algorithm<br>
- Probabilistic Supervised Learning
- Support Vector machines

5.8 Unsupervised Learning Algorithms<br>
- Principal Component Analysis
- K-means clustering

5.9 Stochastic Gradient Descent<br>
5.10 Building a Machine Learning Algorithm<br>
5.11 Challenge Motivating Deep Learning<br>
- The curse of Dimensionality
- Local Constancy and Smoothness Regularization
- Manifold learning

